{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self,img_height, img_width):\n",
    "        super().__init__()\n",
    "        # Add these layers for a faster and better convergence cuz duh...\n",
    "        # Also add batchn Normalisation after convulation layers, it helps in converging faster for better resolution images.\n",
    "        # Attribute extraction\n",
    "        self.c2d1 = nn.Conv2d(in_channels = 3, out_channels = 6, kernel_size = 5)\n",
    "        self.c2d2 = nn.Conv2d(in_channels = 6, out_channels = 12, kernel_size = 5)\n",
    "        self.fc1 = nn.Linear(in_features = ((img_height-8)*(img_width-8))*12, out_features = 64)\n",
    "#         self.fc1 = nn.Linear(in_features = img_height*img_width*3, out_features = 64)\\n\",\n",
    "        self.fc2 = nn.Linear(in_features = 64, out_features = 64)\n",
    "        self.out = nn.Linear(in_features = 64, out_features = 2)\n",
    "    def forward(self, t):\n",
    "        t = F.relu(self.c2d1(t))\n",
    "        t = F.relu(self.c2d2(t))\n",
    "        t = t.flatten(start_dim = 1)\n",
    "        t = F.relu(self.fc1(t))\n",
    "        t = F.relu(self.fc2(t))\n",
    "        t = self.out(t)\n",
    "        return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experience = namedtuple('Experience',('state','action','next_state','reward'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Experience(2,3,1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Experience(state=2, action=3, next_state=1, reward=4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory():\n",
    "    def __init__(self,capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.push_count = 0\n",
    "    def push(self,experience):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(experience)\n",
    "        else:\n",
    "            self.memory[self.push_count%self.capacity]=experience\n",
    "        self.push_count +=1\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    def can_provide_sample(self, batch_size):\n",
    "        return len(self.memory)>=batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpsilonGreedyStrategy():\n",
    "    def __init__(self,start,end,decay):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.decay = decay\n",
    "    def get_exploration_rate(self, current_step):\n",
    "        return self.end + (self.start-self.end)*math.exp(-1*current_step*self.decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, strategy, num_actions, device):\n",
    "        self.current_step = 0\n",
    "        self.device = device\n",
    "        self.strategy = strategy\n",
    "        self.num_actions = num_actions\n",
    "    def select_action(self, state, policy_net):\n",
    "        rate = strategy.get_exploration_rate(self.current_step)\n",
    "        self.current_step +=1\n",
    "        \n",
    "        if rate > random.random():\n",
    "            # explore\n",
    "            action = random.randrange(self.num_actions)\n",
    "            return torch.tensor([action]).to(device)\n",
    "        else:\n",
    "            # exploit\n",
    "            with torch.no_grad():\n",
    "                return policy_net(state).argmax(dim = 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CartPoleEnvManager():\n",
    "    def __init__(self, device=torch.device(\"cpu\")):\n",
    "        self.device = device\n",
    "        self.env = gym.make('CartPole-v0').unwrapped\n",
    "        self.env.reset()\n",
    "        self.current_screen = None\n",
    "        self.done = False\n",
    "        \n",
    "    def reset(self):\n",
    "        self.env.reset()\n",
    "        self.current_screen = None\n",
    "    \n",
    "    def close(self):\n",
    "        self.env.close()\n",
    "    \n",
    "    def render(self, mode = 'human'):\n",
    "        return self.env.render(mode)\n",
    "    \n",
    "    def num_actions_available(self):\n",
    "        return self.env.action_space.n\n",
    "    \n",
    "    def take_action(self,action):\n",
    "        useless, reward, self.done, uselessPart2 = self.env.step(action.item())\n",
    "        return torch.tensor([reward], device = self.device)\n",
    "    \n",
    "    def just_starting(self):\n",
    "        return self.current_screen is None\n",
    "    \n",
    "    def get_state(self):\n",
    "        if self.just_starting() or self.done:\n",
    "            self.current_screen = self.get_processed_screen()\n",
    "            black_screen = torch.zeros_like(self.current_screen)\n",
    "            return black_screen\n",
    "        else:\n",
    "            s1 = self.current_screen\n",
    "            s2 = self.get_processed_screen()\n",
    "            self.current_screen = s2\n",
    "            return s2-s1\n",
    "        \n",
    "    def get_screen_height(self):\n",
    "        screen = self.get_processed_screen()\n",
    "        return screen.shape[2]\n",
    "    \n",
    "    def get_screen_width(self):\n",
    "        screen = self.get_processed_screen()\n",
    "        return screen.shape[3]\n",
    "    \n",
    "    def get_processed_screen(self):\n",
    "        screen = self.render('rgb_array').transpose((2, 0, 1)) # PyTorch expects CHW\n",
    "        print(screen.shape)\n",
    "        screen = self.crop_screen(screen)\n",
    "        return self.transform_screen_data(screen)\n",
    "    \n",
    "    def crop_screen(self, screen):\n",
    "        screen_height = screen.shape[1]\n",
    "        top = int(screen_height * 0.4)\n",
    "        bottom = int(screen_height * 0.8)\n",
    "        screen = screen[:,top:bottom,:]\n",
    "        return screen\n",
    "    \n",
    "    def transform_screen_data(self, screen):       \n",
    "        # Convert to float, rescale, convert to tensor\n",
    "        screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "        screen = torch.from_numpy(screen)\n",
    "    \n",
    "        # Use torchvision package to compose image transforms\n",
    "        resize = T.Compose([\n",
    "            T.ToPILImage()\n",
    "            ,T.Resize((40,90))\n",
    "            ,T.ToTensor()\n",
    "        ])\n",
    "    \n",
    "        return resize(screen).unsqueeze(0).to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-09-15 19:26:38,670] Making new env: CartPole-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n"
     ]
    }
   ],
   "source": [
    "em = CartPoleEnvManager()\n",
    "state = em.get_state()\n",
    "state = em.get_state()\n",
    "state = em.get_state()\n",
    "# print(state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "em.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\nem = CartPoleEnvManager(device)\\nem.reset()\\nscreen = em.render(\\'rgb_array\\')\\n\\nplt.figure()\\nplt.imshow(screen)\\nplt.title(\\'Non-processed screen example\\')\\nplt.show()\\nem.close()'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "em = CartPoleEnvManager(device)\n",
    "em.reset()\n",
    "screen = em.render('rgb_array')\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(screen)\n",
    "plt.title('Non-processed screen example')\n",
    "plt.show()\n",
    "em.close()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"screen = em.get_processed_screen()\\n\\nplt.figure()\\nplt.imshow(screen.squeeze(0).permute(1, 2, 0).cpu(), interpolation='none')\\nplt.title('Processed screen example')\\nplt.show()\\nem.close()\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''screen = em.get_processed_screen()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(screen.squeeze(0).permute(1, 2, 0).cpu(), interpolation='none')\n",
    "plt.title('Processed screen example')\n",
    "plt.show()\n",
    "em.close()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"screen = em.get_state()\\n    \\nplt.figure()\\nplt.imshow(screen.squeeze(0).permute(1, 2, 0).cpu(), interpolation='none')\\nplt.title('Starting state example')\\nplt.show()\\nem.close()\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''screen = em.get_state()\n",
    "    \n",
    "plt.figure()\n",
    "plt.imshow(screen.squeeze(0).permute(1, 2, 0).cpu(), interpolation='none')\n",
    "plt.title('Starting state example')\n",
    "plt.show()\n",
    "em.close()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for i in range(5):\\n    em.take_action(torch.tensor([1]))\\nscreen = em.get_state()\\n\\nplt.figure()\\nplt.imshow(screen.squeeze(0).permute(1, 2, 0).cpu(), interpolation='none')\\nplt.title('Non starting state example')\\nplt.show()\\nem.close()\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for i in range(5):\n",
    "    em.take_action(torch.tensor([1]))\n",
    "screen = em.get_state()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(screen.squeeze(0).permute(1, 2, 0).cpu(), interpolation='none')\n",
    "plt.title('Non starting state example')\n",
    "plt.show()\n",
    "em.close()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QValues():\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_current(policy_net, states, actions):\n",
    "        return policy_net(states).gather(dim = 1, index = actions.unsqueeze(-1))\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_next(target_net, next_states):\n",
    "        # we flatten the values of the pixels in each of the next_states and then\n",
    "        # compare the max of them to 0 as the ending state will have a blank black \n",
    "        # screen and then store those locations(indices of states) as True\n",
    "        final_state_locations = next_states.flatten(start_dim = 1).max(dim = 1)[0].eq(0).type(torch.bool)\n",
    "        # just flipping the above tensor's bool values\n",
    "        non_final_state_locations = (final_state_locations == False)\n",
    "        # tensors allow slicing with a tensor of bool values, not just indices\n",
    "        non_final_states = next_states[non_final_state_locations]\n",
    "        batch_size = next_states.shape[0]\n",
    "        # initialising a tensor of length of states made of zeros\n",
    "        values = torch.zeros(batch_size).to(QValues.device)\n",
    "        # sets values of q* function only in the states without a terminal \n",
    "        # ending and then returns the max out of them\n",
    "        values[non_final_state_locations] = target_net(non_final_states).max(dim = 1)[0].detach()\n",
    "        return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(values, moving_avg_period):\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    plt.title('Training.....')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(values)\n",
    "    moving_avg = get_moving_average(moving_avg_period, values)\n",
    "    plt.plot(moving_avg)\n",
    "    plt.pause(0.001)\n",
    "    print(\"Episode\", len(values),\"\\n\",moving_avg_period, \"episode moving avg: \",moving_avg[-1])\n",
    "    if is_ipython: display.clear_output(wait = True)\n",
    "\n",
    "def get_moving_average(period, values):\n",
    "    values = torch.tensor(values, dtype = torch.float)\n",
    "    if (len(values)>= period):\n",
    "        moving_avg = values.unfold(dimension = 0, size = period, step = 1).mean(dim = 1).flatten(start_dim = 0)\n",
    "        moving_avg = torch.cat((torch.zeros(period-1), moving_avg))\n",
    "        return moving_avg.numpy()\n",
    "    else:\n",
    "        moving_avg = torch.zeros(len(values))\n",
    "        return moving_avg.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tensors(experiences):\n",
    "    batch = Experience(*zip(*experiences))\n",
    "    \n",
    "    t1 = torch.cat(batch.state)\n",
    "    t2 = torch.cat(batch.action)\n",
    "    t3 = torch.cat(batch.reward)\n",
    "    t4 = torch.cat(batch.next_state)\n",
    "    \n",
    "    return (t1,t2,t3,t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "gamma = 0.999\n",
    "eps_start = 1\n",
    "eps_end = 0.01\n",
    "eps_decay = 0.001\n",
    "target_update = 10\n",
    "memory_size = 100000\n",
    "lr = 0.001\n",
    "num_episodes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n",
      "(3, 400, 600)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dd3xV9f3H8dcnA5IASQgjYQQZsleYKijWQUUBt+CstrXYYZ2tWtv+tNa22jpwtFQcra0D3AqIIi5AK5aRhL1kc4EwkgAh+/v7415sxAABcu+54/18PPLIuSf33PPJJbzvud/7PZ9jzjlERCR2xHldgIiIhJaCX0Qkxij4RURijIJfRCTGKPhFRGKMgl9EJMYo+EUAM5tuZtfW931FwpFpHr9EKjPbW+NmClAGVAVu3+CcezH0VYmEPwW/RAUzWwdc75ybWcvPEpxzlaGvSiQ8aahHoo6ZfcfMNpnZnWa2FfiHmTU1s6lmVmBmuwPLbWts84mZXR9Yvs7M5pjZQ4H7rjWzc4/xvh3MbJaZ7TGzmWb2VzN7IYRPh8i3KPglWmUBGcAJwDj8f+v/CNxuB+wHnjzM9icBK4DmwJ+BZ83MjuG+LwFfAs2Ae4Frjvk3EqknCn6JVtXAPc65MufcfufcTufc6865EufcHuAPwOmH2X69c+5p51wV8DzQCsg8mvuaWTtgEPB/zrly59wc4J36+gVFjpWCX6JVgXOu9MANM0sxs6fMbL2ZFQOzgHQziz/E9lsPLDjnSgKLjY/yvq2BXTXWAWw8yt9DpN4p+CVaHTxr4XagK3CScy4VGBZYf6jhm/rgAzLMLKXGuuwg7k+kThT8Eiua4B/XLzSzDOCeYO/QObcemAfca2YNzOwUYHSw9ytyJAp+iRXjgWRgB/AF8F6I9nsVcAqwE7gfmIz/fAPAfy6CmZ0WWD6t5rkJZna3mU2vcXu6md1d27YiR0Pz+EVCyMwmA8udc0F/xyFyKDriFwkiMxtkZp3MLM7MRgAXAG95XZfEtgSvCxCJclnAG/jn8W8CfuKcW+htSRLrNNQjIhJjNNQjIhJjImKop3nz5q59+/ZelyEiElHmz5+/wznX4uD1ERH87du3Z968eV6XISISUcxsfW3rNdQjIhJjFPwiIjFGwS8iEmMU/CIiMUbBLyISYxT8IiIxRsEvIhJjFPwiImFo594y7puylH1llfX+2Ap+EZEw45zjztfzeWHuejbt3l/vj6/gFxEJMy/O3cDMZdu5a0Q3umY1qffHV/CLiISR1dv3cP+0pQzr0oLrhrQPyj4U/CIiYaKssoqbXs4lpUECD13ah7g4C8p+IqJJm4hILHhkxkqW+op5+nsDaZmaFLT96IhfRCQMfLZ6B0/N+oqrTmrH8B6ZQd2Xgl9ExGO795Vz+yt5dGzRiN+M7BH0/Sn4RUQ85Jzj7jcXsXNfGY9f3o/kBvFB36eCX0TEQ6/O28T0xVv5xXe70qtNWkj2qeAXEfHI2h37uHfKEoZ0asaPTusYsv0q+EVEPFBRVc0tkxaSGB/Hw2P6Bm3qZm00nVNExAOPzVxF3qYiJlzVn1ZpySHdd1CD38zWAXuAKqDSOTfQzDKAyUB7YB0wxjm3O5h1iIiEky/X7uJvn6xmzMC2nNu7Vcj3H4qhnjOccznOuYGB23cBHzrnOgMfBm6LiMSEov0V3Do5l+yMFO4Z3dOTGrwY478AeD6w/DxwoQc1iIh44v/eXszW4lLGj82hUUNvRtuDHfwOmGFm881sXGBdpnPOF1jeCtR6ipqZjTOzeWY2r6CgIMhliogE31sLN/N27hZuOasz/do19ayOYL/cnOqc22xmLYEPzGx5zR8655yZudo2dM5NBCYCDBw4sNb7iIhEio27SvjtW4sZ1L4pPz3jRE9rCeoRv3Nuc+D7duBNYDCwzcxaAQS+bw9mDSIiXqusqubWybkAPDImh/gQTt2sTdCC38wamVmTA8vAd4HFwDvAtYG7XQu8HawaRETCwd8+WcO89bu5/6JeZGekeF1OUId6MoE3zezAfl5yzr1nZv8FXjGzHwLrgTFBrEFExFMLNuzmsQ9XcWFOay7IaeN1OUAQg9859xXQt5b1O4GzgrVfEZFwsbesklsm5ZKVmsR9F/byupyv6cxdEZEgufedJWzaXcLkG04hNSnR63K+pl49IiJBMDV/C6/N38SNZ5zIoPYZXpfzDQp+EZF6tqVwP3e/sYic7HR+flZnr8v5FgW/iEg9qqp23Do5l6pqx2OX55AYH34xqzF+EZF6NHHWV8xdu4u/XNqHE5o18rqcWoXfS5GISIRatKmIh2esYGTvVlw6oK3X5RySgl9EpB6UlFdy86SFtGjSkD9c1IvAOUxhSUM9IiL14P5py1i7cx8vXn8S6SkNvC7nsHTELyJynGYs2cpLczcwblhHhnRq7nU5R6TgFxE5DtuLS7nz9Xx6tUnl9uFdvS6nThT8IiLHqLracfureeyvqGL82H40SIiMSI2MKkVEwtA/Pl/H7FU7+O2oHpzYsrHX5dSZgl9E5Bgs8xXz4PTlnN09kysHt/O6nKOi4BcROUqlFVXcPGkhaSmJPHhJ77CeulkbTecUETlKD0xfzspte3n+B4Np1rih1+UcNR3xi4gchY+Xb+efn6/jB0M7cHqXFl6Xc0wU/CIidbRjbxm/fC2PbllNuGNEZEzdrI2GekRE6sA5xx2v5VNcWsmL159MUmK81yUdMx3xi4jUwQtfrOej5du5+9xudM1q4nU5x0XBLyJyBKu27eH+acs4vUsLrh3S3utyjpuCX0TkMMoqq7hpUi6NGybwl8v6RNzUzdpojF9E5DAeen8Fy3zFPHvtQFo2SfK6nHqhI34RkUOYs2oHT89ey9Unt+Os7plel1NvFPwiIrXYva+c21/NpVOLRvz6vB5el1OvNNQjInIQ5xx3vZHPrn3lPHvtIJIbRO7UzdroiF9E5CCvzNvI+0u28ctzutKrTZrX5dQ7HfGLiASUVVbxwhcbeOj9FQzp1IzrT+3odUlBEfTgN7N4YB6w2Tk3ysw6AJOAZsB84BrnXHmw6xAROZTqasc7eVt4aMYKNu3ez9ATm/HomBzi4iJ/6mZtQnHEfzOwDEgN3H4QeNQ5N8nM/g78EJgQgjpERL5l1soCHpi+nKW+Ynq0SuVfP+jNsAhtvlZXQQ1+M2sLjAT+ANxm/jMfzgSuDNzleeBeFPwiEmKLNxfxwPTlzFm9g7ZNkxk/Nofz+7aO2qP8moJ9xD8euAM40NiiGVDonKsM3N4EtKltQzMbB4wDaNcusq5uIyLha8POEh6asYJ38rbQNCWR347qwdUnt6NhQnTN3DmcoAW/mY0Ctjvn5pvZd452e+fcRGAiwMCBA109lyciMWbn3jKe+Gg1L85dT3yc8bMzOnHD6Z1ITUr0urSQC+YR/1DgfDM7D0jCP8b/GJBuZgmBo/62wOYg1iAiMa6kvJJnZ6/lqVlfUVJeydhB2dxydhcyU6Oj/cKxCFrwO+d+BfwKIHDE/wvn3FVm9ipwKf6ZPdcCbwerBhGJXZVV1Uyet5HxM1dRsKeM4T0yuXNEV05sGdktleuDF/P47wQmmdn9wELgWQ9qEJEo5Zzj/SXb+PP7y/mqYB8DTmjKhKv6M7B9htelhY2QBL9z7hPgk8DyV8DgUOxXRGLLf9ft4k/vLmPBhkI6tWjExGsGMLxHZlS0Uq5POnNXRCLeqm17ePC95cxctp3M1IY8cHFvLh3QloR4daWpjYJfRCKWr2g/j36wktfmb6JRgwR+eU5XfjC0Q9Q1VatvCn4RiThF+yv4+6dreG7OWqqd47ohHbjxzBPJaNTA69IigoJfRCJGWWUV//7Pep78eDWFJRVcmNOa27/bleyMFK9LiygKfhEJe9XVjrdyN/PwjJVsLtzPaZ2bc+eIblHZMjkUFPwiEracc3y6soAH3/Nf97ZXm1QevKQPp3Zu7nVpEU3BLyJhKX9TIQ9MX87na3aSnZHMY5fnMLpPbDRRCzYFv4iElfU79/GX91cwNd9HRqMG3DO6B1eddAINEjQ1s74o+EUkbDz0/gr+/ukaEuPj+PmZJzJuWEeaxGATtWBT8ItIWFhTsJcnP17Neb2zuHd0T1rGcBO1YNN7JxEJC1PzfJjB/41S6Aebgl9EPOecY0r+Fga1zyArTaEfbAp+EfHcim17WL19L6P7tPK6lJig4BcRz03N8xFncG5vBX8oKPhFxFMHhnmGntic5o0bel1OTFDwi4inFm0uYv3OEkZpmCdkFPwi4qmp+T4S441zemZ5XUrMUPCLiGeqqx1T87ZwWucWpKeopXKoKPhFxDMLN+5mS1Epo/tqmCeUFPwi4pkpeT4aJsRxdvdMr0uJKQp+EfFEVbVj2iIfZ3RtqX48IabgFxFPzF27k4I9ZYzu29rrUmKOgl9EPDElz0dKg3jO7NbS61JijoJfREKuoqqa9xb7OLt7JskN4r0uJ+bUqS2zmbUAfgS0r7mNc+4HwSlLRKLZZ6t3sLukQsM8HqlrP/63gdnATKAqeOWISCyYkuejSVICw7ro2rleqGvwpzjn7gxqJSISE8oqq5ixZCvn9MqiYYKGebxQ1zH+qWZ2XlArEZGY8OmKAvaUVao3j4fqGvw34w//UjPbE/gqPtwGZpZkZl+aWZ6ZLTGz3wXWdzCzuWa22swmm5nO0xaJIVPzfTRNSWToiRrm8Uqdgt8518Q5F+ecSwosN3HOpR5hszLgTOdcXyAHGGFmJwMPAo86504EdgM/PJ5fQEQiR0l5JR8s3ca5vVuRGK9JhV6p8zNvZueb2UOBr1FHur/z2xu4mRj4csCZwGuB9c8DFx5lzSISoT5avp39FVUa5vFYnYLfzB7AP9yzNPB1s5n9qQ7bxZtZLrAd+ABYAxQ65yoDd9kEtDnEtuPMbJ6ZzSsoKKhLmSIS5qbm+WjRpCEndWjmdSkxra5H/OcBw51zzznnngNGACOPtJFzrso5lwO0BQYD3epamHNuonNuoHNuYIsWLeq6mYiEqT2lFXy0Yjsje7ciPs68LiemHc0gW3qN5bSj2YlzrhD4GDgFSDezA9NI2wKbj+axRCQyzVy2jfLKarVgDgN1Df4/AQvN7J9m9jwwH/jD4TYwsxZmlh5YTgaGA8vwvwBcGrjbtfhPDhORKDclz0eb9GT6ZTf1upSYV6cTuJxzL5vZJ8CgwKo7nXNbj7BZK+B5M4vH/wLzinNuqpktBSaZ2f3AQuDZYytdRCJFYUk5s1YW8INTOxCnYR7PHTb4zaybc265mfUPrNoU+N7azFo75xYcalvnXD7Qr5b1X+Ef7xeRGPH+kq1UVjtG91FvnnBwpCP+24BxwMO1/OzA1EwRkcOakufjhGYp9GpzpNN/JBQOG/zOuXGBxXOdc6U1f2ZmSUGrSkSixo69ZXy+Zgc//c6JmGmYJxzU9cPdz+u4TkTkG6Yv8lHtUAvmMHKkMf4s/CdYJZtZP+DAy3UqkBLk2kQkCkzJ89G5ZWO6ZjXxuhQJONIY/znAdfjn2z9SY/0e4O4g1SQiUcJXtJ//rt/FrWd38boUqeFIY/zP45+SeYlz7vUQ1SQiUWJavg/nUG+eMFPXefyvm9lIoCeQVGP9fcEqTEQi39R8Hz1bp9KxRWOvS5Ea6tqk7e/AWODn+Mf5LwNOCGJdIhLhNu4qIXdjoT7UDUN1ndUzxDn3PWC3c+53+HvuaNBORA5pSv4WAEb21jBPuKlr8B+Yw19iZq2BCvwtGUREajU1z0e/dulkZ2gCYLipa/BPCTRc+wuwAFgHvBSsokQksq0p2MtSX7FaNISpI364a2ZxwIeB1sqvm9lUIMk5VxT06kQkIk3N82EGIzWbJywd8YjfOVcN/LXG7TKFvogcinOOd/I2M7h9Bpmp6uwSjuo61POhmV1iarQhIkewfOse1hTsY5Rm84Stugb/DcCrQJmZFZvZHjMrDmJdIhKhpuZvIT7OOLdXltelyCHU9QQuNdmIcKUVVfxh2jIaNUwgJzud/u3Saam34VLPnHNMyfMxpFMzmjdu6HU5cgh1Cn4zG1bbeufcrPotR4LlL++v4N9frCcx3qiocgC0TkuiX7um5GSnk9Mund5t0khKjPe4UolkizYXsWFXCTeecaLXpchh1Cn4gV/WWE7CfwWt+ehCLBFh1soCnp2zlmtPOYFfndedJVuKyd1YyMINu8ndWMi0RT4AEuKMbq2a0C/b/2LQr106HZo3Ug91qbMpeVtIjDfO6alhnnBW16Ge0TVvm1k2MD4oFUm92rWvnNtfzaNzy8b86rzuJCXGM+CEpgw4oSnQAYCCPWXkbiwkd+NuFm4o5M2Fm/n3F+sBSEtOpG92Ov0C7wpy2qbTtFEDD38jCVfV1Y6p+T6GdW5BWkqi1+XIYdT1iP9gm4Du9VmI1D/nHHe+nk9RSQXPf3/wIYdxWjRpyPAemQzvkQlAVbVj9fa9X78Q5G4s5PGPVuH8I0R0aN7o63cEOdnpdMtKpUFCXecJSLRasGE3vqJS7hzRzetS5AjqOsb/BP5r7IJ/JlAO/jN4JYy9/OVGPli6jd+M7E6P1nW/1ml8nNE1qwlds5owdlA7APaWVZK/qTAwRFTI7FU7eHPhZgAaJsTRq03a/94VZKfTJj1ZQ0QxZkreFhomxHF24ABCwlddj/jn1ViuBF52zn0WhHqknqzevpf7pi7htM7N+cHQDsf9eI0bJjCkU3OGdGoO+N9NbC7c//ULQe7GQv71xXqembMW8L+LqPmuoE/bdBo3PNY3mBLuqqod0xZt5cxuLfXvHAHqOsb/vJm1CCwXBLckOV7lldXcMnkhyYnxPHRZX+Li6v/I28xo2zSFtk1TGBXox1JeWc3yrcXfeDH4YOk2AOIMumQ2ISc7nQEnNOWCnDYaHooic7/ayY69ZWrBHCGOdM1dA+4BbsQ/xGNmVgk8oYuwhK9HZ65k8eZi/n71gJCeMt8gIY4+bf1H9987xb9u975ycjf974Xg3UU+Jv13Iy99uYEnr+xPm/TkkNUnwTMl30dKg3jO6NrS61KkDo50xH8rMBQY5JxbC2BmHYEJZnarc+7RYBcoR+c/a3by90/XcMXgbEaEwZmTTRs14IyuLb8OhOpqx7uLfdz1+iJGPj6bR8fkcEY3hUUkq6iqZvpiH8N7ZJLcQOeBRIIjvde+BrjiQOgDOOe+Aq4GvhfMwuToFZVUcNsruXRo1ojfjurhdTm1ioszRvVpzZSfn0qrtGS+/8//8uB7y6msqva6NDlGc1bvoLCkQi2YI8iRgj/RObfj4JWBcX5N1A0jzjnufnMRBXvKGH95DikNwvsDtg7NG/HmT4dwxeBsJnyyhiufmcu24tIjbxhFqqod//xsLY9+sBJ3YK5sBJqa56NJUgKndWnudSlSR0dKh/Jj/JmE2OsLNjNtkY87RnSlT9t0r8upk6TEeP50cR8Gtc/g128u5rzHZvPY5f04tXP0B8iKrXu48/V8cjcWApCeksj362H2VaiVVlQxY8lWRvTKomGChnkixZGO+PsGunEe/LUH6H24Dc0s28w+NrOlZrbEzG4OrM8wsw/MbFXge9P6+mVi1fqd+7jn7cWc1CGDG4Z18rqco3Zx/7a8c+NQmjZqwDXPzWX8zJVUVUfuEfDhlFdWM37mSkY9MZsNu0p47PIczu6eyR+mLWP++t1el3fUZq0sYE9ZpVowR5jDBr9zLt45l1rLVxPn3JGGeiqB251zPYCTgZ+ZWQ/gLvxX9OoMfBi4LceooqqamyflEh9nPDo2h/ggTN0Mhc6ZTXjnxqFclNOG8TNXcd0/vmTH3jKvy6pXeRsLGf3EHMbPXMV5vVvxwa3DuCCnDQ+P6Uvr9GRufGkBOyPsd56S7yOjUQOGdGrmdSlyFII2kdo553POLQgs7wGWAW2AC4DnA3d7HrgwWDXEgic+Wk3uxkL+eHFvWkf41MiUBgk8PKYvD1zcmy/X7mLk47P5cu0ur8s6bvvLq/jDtKVc9LfPKNpfwTPfG8hjl/ejWaBtcVpyIn+7qj8795Vz86TciHm3U1Jeycyl2zi3VxaJ8TonI5KE5F/LzNoD/YC5QKZzzhf40Vag1vO7zWycmc0zs3kFBTpnrDbz1u3iyY9WcUn/tl+fRBXpzIzLB7fjzZ8OJaVBAlc8/QUTPllDdYSE4cE+X7ODEY/N4unZa7l8cDtm3Das1pYGvdqk8fsLejJn9Q7Gz1zpQaVH76Pl29lfURU1f3uxJOjBb2aNgdeBW5xz37hql/NPZaj1f7RzbqJzbqBzbmCLFi2CXWbEKS6t4JbJubRtmsK954fn1M3j0aN1Ku/cOJQRPbN48L3lXP+veezeFznzCYpLK/jVG4u48um5ALz0o5P440W9SU069Ajp2EHtuGxAW574aDUfL98eqlKP2ZS8LbRs0pDBHTK8LkWOUlCD38wS8Yf+i865NwKrt5lZq8DPWwHh/xcehu55ewm+olIeHZtDk8OESSRrkpTIk1f2474LejJ7VQGjnpjDwg3h/wHozKXbGP7Ip0z+7wbGDevIezcP+7rH0ZH8/sJedG+Vyi2Tc9m4qyTIlR67PaUVfLyigPN6t4rYz5ViWdCCP9Du4VlgmXPukRo/ege4NrB8LfB2sGqIVm/nbubNhZv5+ZknBvrqRy8z43untOe1Hw/BDMY89R+em7M2LOe979xbxk0vL+T6f82jaUoD3vzpUO4+r/tRnc2alBjPhKv6U13t+NlLCyirrApixcfug6XbKK+sVm+eCBXMI/6h+M/8PdPMcgNf5wEPAMPNbBVwduC21NGm3SX85q3F9G+XHlOXt+ubnc60n5/G6V1act/UpfzkhQUUl1Z4XRbgP3nu7dzNnP3Ip0xf7OPWs7vwzo2n0jf72M6naN+8EQ+N6Uv+piLum7K0nqutH1PyttAmPZn+7SLjnBH5pqCd3umcmwMc6j3gWcHabzSrqnbcNjkP52D82H4kxNhMirSURJ7+3gCemb2WB95bzqjH5/C3q/rTq02aZzX5ivbzmzcX8+Hy7eRkp/PnS/vQJbPJcT/uOT2zuGFYR56a9RUD2zflon5t66Ha+lFYUs7sVTv44akddM2FCBVbyRHh/v7pGr5ct4v7LuhJu2YpXpfjCTPjR8M6MnncyZRXVnPxhM95ce76kA/9VFc7Xpy7nuGPzOKzNTv4zcjuvP6TIfUS+gf88pyuDO6Qwa/eWMSKrXvq7XGP13uLt1JZ7TTME8EU/BEid2Mhj36wktF9W3NRvzZel+O5ge0zmHbTqZzcsRm/fnMxt0zOZV9ZZUj2vXbHPq54+gt+/eZi+rRNY8Ytp3P9aR3r/UPOhPg4nryiH02SEvnJC/PZEyZDW1PzfbRvlkLPo7iqm4QXBX8E2FdWyS2TFpKZmsT9F/bS2+uAZo0b8s/rBvGL73ZhSt4Wzn9yTlCPjCurqpk4aw0jxs9iqa+YBy/pzYvXnxTUd18tU5N48op+rN9Vwp2v53v+oXbBnjI+X7OD0X1b6+8wgin4I8B9U5ayflcJj4zpS1pydE7dPFZxccaNZ3bmhetPomh/JRf8dQ6vzd9U7/tZ5ivm4gmf88d3lzOsSwtm3nY6Ywe1C0n4ndSxGXec05V3F23luc/WBX1/hzN9sY9qh4Z5IpyCP8xNX+Rj8ryN/PQ7nTipo/qhHMqQTs159+ZTyclO5xev5nHHa3nsLz/+qZBllVU8MmMFo5+Yw+bd+3nyyn5MvCa0VzYDGDesI9/tkcmf3l3GvHXetbGYmuejS2bjev0sQ0JPwR/GfEX7ueuNRfRpm8YtZ3fxupyw17JJEi9efzI/P/NEXp2/iYv+9hlrCvYe8+Mt2LCbUY/P4fGPVjO6b2tm3nY6o/p4M8RhZvzlsr60aZrMz15a4EkDO1/Rfr5ct0sXXIkCCv4wVV3tuP2VPMorq3ns8n5qglVH8XHG7d/tyj+uG8S24lLOf2IO7+RtOarHKCmv5L4pS7lkwufsK6vkH9cN4tGxOTRt1CBIVddNWnIiE64aQGFJBTe9vDDkzdym5ftbbKkFc+RTmoSpZ+Z8xedrdnLv+T3o0LyR1+VEnO90bcm0m06jW6tUbnp5Ib95a1GdzoL9bPUOzhk/i+c+W8vVJ53A+7cOC6trAvdoncrvL+zF52t28sgHK0K67yn5Pnq1SdXfYxRQ8IehxZuL+Mv7KzinZyZjBmZ7XU7Eap2ezKRxJzNuWEde+GIDl074Dxt21t7/pmh/BXe+ls9Vz8wlIS6OyeNO5vcX9grLPkhjBmYzdmA2f/14DR8u2xaSfW7YWeK/noCGeaKCgj/M7C+v4uZJC8lo1IAHLu6jKXPHKTE+jrvP687Eawawfuc+Rj4xm/eXbP3Gfd5fspXhj3zKaws28ePTOzH95tPC/oP0313Qkx6tUrk1RM3cpi7yD5eN7NMq6PuS4FPwh5k/vruMNQX7ePgy78eUo8l3e2Yx7abT6NC8ETf8ez73T12Kr2g/P3txATf8ez7NGjfkrZ8O5a5zu5GUGP7Xjk1KjOfvVw/AAT95cT6lFcFt5jYlz0f/dum0bRqbZ4xHGwV/GPlw2Tb+/cV6fnRah5i44HioZWek8OqPT+G6Ie15Zs5ahjzwER8s3cYvvtuFd24cSu+23vX8ORbtmqXwyJgcFm8u5ndBbOa2evtelvmKdcGVKBK0Jm1ydLbvKeWO1/Lp3iqVX5zT1etyolbDhHjuPb8ng9pn8O5iH7ee3ZkTW0bunPThPTL5yXc6MeGTNQw8oSmXDKj/Zm5T87dgpmGeaKLgDwPOOX75aj57yyqZdHkODRPCf6gh0o3s0ypqguz24V3I3VDIr99aRI/WqXRvVX89dJxzTMnbwkkdMkJ+0poEj4Z6wsDzn6/j05UF/GZkdzrrjEg5SgnxcTx+RT9SA83c6vM6Bcu37mFNwT4N80QZBb/HVmzdwx+nL+fMbi25+uQTvC5HIlSLJg158sr+bNy9nzterb9mblPythAfZ5zbK6teHk/Cg4LfQ6UV/qmbqUkJ/PlSTd2U4zO4QwZ3jejGe0u28szstcf9eM45pub7GNKpGc0aN6yHCiVcKPg99Of3VrB860LytkEAAAq/SURBVB7+cllfmus/ltSD60/rwIieWTzw3nK+XHt8zdzyNxWxYVeJOnFGIQW/Rz5dWcBzn63luiHtOaNr+LQEkMhmZvz5sj5kN03mxpcWsH1P6TE/1pS8LSTGG+f01DBPtFHwe2Dn3jJ+8WoeXTIbc9e53bwuR6JMalIiE64eQHGpv5lbZVX1UT9GdbVj2iIfp3dpoWtARCEFf4g557jz9UUUlVQwfmy/iDhLVCJP91ap/OHC3nzx1S4e/mDlUW8/f8NufEWlGuaJUgr+EHvpyw3MXLaNO0Z0pYeuWSpBdMmAtlwxuB0TPlnDB0uPrpnb1LwtNEyI46zumUGqTryk4A+h1dv38vupSzmtc3N+MLSD1+VIDLhndA96tUnltldyD9mZ9GCVVdVMW+TjrO4tadxQ53hGIwV/iJRXVnPL5IUkJ8bz0GV9iYvT1E0JvqTEeCZcNYA4M378Qt2auc1du4sde8vVgjmKKfhD5JEPVrJ4czEPXNJHp75LSGVnpPDo2L4s9RVzz9tLjnj/qflbaNQgPqwuQCP1S8EfZM45Zq8q4KlZa7hicDtNjRNPnNktk5+d0YnJ8zbyyryNh7xfRVU10xdvZXiPTE08iGIawDsO1dWOHfvK2FpU6v8qLsVXVMq2Iv93/+39lFZU07F5I347qrvXJUsMu214VxZuKOS3by2mZ+tUerb+dhvqOat3UFhSod48US5owW9mzwGjgO3OuV6BdRnAZKA9sA4Y45zbHawajkdFVTXbikvZFgjzA+HuK/7f8rbiUioPuuB1YrzRskkSrdKS6Nk6lbO6tSQrLYmRfVqR0kCvs+Kd+Djj8Sv6MfLx2fz0xQW8c+Op35qjPyVvC6lJCZzWRdeDiGbBTKJ/Ak8C/6qx7i7gQ+fcA2Z2V+D2nUGsoVb7y6u+Pho/cKS+tahGwBeXsmNvGQf3uUpOjKdVWhJZaUmc1CGDrDR/wGemJtEqLZmstCSaNWqgD24lbDVv3JC/Xtmfyyd+wS9fzeOpawZ83SOqtKKKGUu2cV7vLLUGj3JBC37n3Cwza3/Q6guA7wSWnwc+IYjBP2PJVpb6ir8O9QNH70X7v922Ni05kaxUf6j3bJ1KVlrS17dbpSWTlZpEanKCGqlJxBvYPoO7zu3G/dOWMXHWV9xweifA30Zkb1mlhnliQKjHHjKdc77A8lbgkGeHmNk4YBxAu3btjmlnr8zbxMxl22jeuCGt0pLIzkhhUPv/HanXDHcNw0gs+eGpHViwYTd/fn8FOdnpnNSxGVPytpDRqAFDOoX3hebl+HmWds45Z2aHbBrunJsITAQYOHDgMTUXf/iyviQ3iKdBgiYvidRkZjx4SR+W+z7jxpcX8tqPT+HDZdu5uH8bEuL1/yXahfpfeJuZtQIIfN8ezJ2lpSQq9EUOoUmgmdve0koumfA5+yuq1JsnRoQ6Fd8Brg0sXwu8HeL9i0gNXbOa8MeLe7FjbzmZqQ0Z1D7D65IkBII5nfNl/B/kNjezTcA9wAPAK2b2Q2A9MCZY+xeRurmoX1sKSypo2SSJeM1IiwnBnNVzxSF+dFaw9ikix+b7ahoYUzQALiISYxT8IiIxRsEvIhJjFPwiIjFGwS8iEmMU/CIiMUbBLyISYxT8IiIxRsEvIhJjFPwiIjFGwS8iEmMU/CIiMUbBLyISYxT8IiIxRsEvIhJjFPwiIjFGwS8iEmMU/CIiMUbBLyISYxT8IiIxRsEvIhJjFPwiIjFGwS8iEmMU/CIiMUbBLyISYxT8IiIxRsEvIhJjFPwiIjHGk+A3sxFmtsLMVpvZXV7UICISq0Ie/GYWD/wVOBfoAVxhZj1CXYeISKxK8GCfg4HVzrmvAMxsEnABsLTe9zT9Lti6qN4fVkQkJLJ6w7kP1PvDejHU0wbYWOP2psC6bzCzcWY2z8zmFRQUhKw4EZFo58URf5045yYCEwEGDhzojulBgvBKKSIS6bw44t8MZNe43TawTkREQsCL4P8v0NnMOphZA+By4B0P6hARiUkhH+pxzlWa2Y3A+0A88Jxzbkmo6xARiVWejPE7594F3vVi3yIisU5n7oqIxBgFv4hIjFHwi4jEGAW/iEiMMeeO7dyoUDKzAmD9MW7eHNhRj+VEOj0f/6Pn4pv0fHxTNDwfJzjnWhy8MiKC/3iY2Tzn3ECv6wgXej7+R8/FN+n5+KZofj401CMiEmMU/CIiMSYWgn+i1wWEGT0f/6Pn4pv0fHxT1D4fUT/GLyIi3xQLR/wiIlKDgl9EJMZEdfDrou5+ZpZtZh+b2VIzW2JmN3tdUzgws3gzW2hmU72uxWtmlm5mr5nZcjNbZmaneF2TV8zs1sD/k8Vm9rKZJXldU32L2uDXRd2/oRK43TnXAzgZ+FkMPxc13Qws87qIMPEY8J5zrhvQlxh9XsysDXATMNA51wt/6/jLva2q/kVt8FPjou7OuXLgwEXdY45zzuecWxBY3oP/P/W3rnMcS8ysLTASeMbrWrxmZmnAMOBZAOdcuXOu0NuqPJUAJJtZApACbPG4nnoXzcFfp4u6xxozaw/0A+Z6W4nnxgN3ANVeFxIGOgAFwD8CQ1/PmFkjr4vygnNuM/AQsAHwAUXOuRneVlX/ojn45SBm1hh4HbjFOVfsdT1eMbNRwHbn3HyvawkTCUB/YIJzrh+wD4jJz8TMrCn+kYEOQGugkZld7W1V9S+ag18Xda/BzBLxh/6Lzrk3vK7HY0OB881sHf4hwDPN7AVvS/LUJmCTc+7Au8DX8L8QxKKzgbXOuQLnXAXwBjDE45rqXTQHvy7qHmBmhn/8dplz7hGv6/Gac+5Xzrm2zrn2+P8uPnLORd1RXV0557YCG82sa2DVWcBSD0vy0gbgZDNLCfy/OYso/KDbk2vuhoIu6v4NQ4FrgEVmlhtYd3fg2sciAD8HXgwcJH0FfN/jejzhnJtrZq8BC/DPhltIFLZuUMsGEZEYE81DPSIiUgsFv4hIjFHwi4jEGAW/iEiMUfCLiMQYBb/EJDOrMrPcGl+HPVPVzH5sZt+rh/2uM7Pmx/s4IsdD0zklJpnZXudcYw/2uw5/58cdod63yAE64hepIXBE/mczW2RmX5rZiYH195rZLwLLNwWubZBvZpMC6zLM7K3Aui/MrE9gfTMzmxHo7/4MYDX2dXVgH7lm9lSglbhI0Cn4JVYlHzTUM7bGz4qcc72BJ/F38TzYXUA/51wf4MeBdb8DFgbW3Q38K7D+HmCOc64n8CbQDsDMugNjgaHOuRygCriqfn9FkdpFbcsGkSPYHwjc2rxc4/ujtfw8H397g7eAtwLrTgUuAXDOfRQ40k/F3+f+4sD6aWa2O3D/s4ABwH/9LWFIBrYf368kUjcKfpFvc4dYPmAk/kAfDfzazHofwz4MeN4596tj2FbkuGioR+Tbxtb4/p+aPzCzOCDbOfcxcCeQBjQGZhMYqjGz7wA7Atc8mAVcGVh/LtA08FAfApeaWcvAzzLM7IQg/k4iX9MRv8Sq5BqdSsF/vdkDUzqbmlk+UAZccdB28cALgcsVGvC4c67QzO4FngtsVwJcG7j/74CXzWwJ8Dn+tr8455aa2W+AGYEXkwrgZ8D6+v5FRQ6m6ZwiNWi6pcQCDfWIiMQYHfGLiMQYHfGLiMQYBb+ISIxR8IuIxBgFv4hIjFHwi4jEmP8HCnu7IVdzgFAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10 \n",
      " 100 episode moving avg:  0.0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "em = CartPoleEnvManager(device)\n",
    "strategy = EpsilonGreedyStrategy(eps_start, eps_end, eps_decay)\n",
    "agent = Agent(strategy, em.num_actions_available(), device)\n",
    "memory = ReplayMemory(memory_size)\n",
    "policy_net = DQN(em.get_screen_height(), em.get_screen_width()).to(device)\n",
    "target_net = DQN(em.get_screen_height(), em.get_screen_width()).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "optimizer = optim.Adam(params = policy_net.parameters(), lr = lr)\n",
    "episode_durations = []\n",
    "for episode in range(num_episodes):\n",
    "    em.reset()\n",
    "    state = em.get_state()\n",
    "    \n",
    "    for timestep in count():\n",
    "        action = agent.select_action(state,policy_net)\n",
    "        reward = em.take_action(action)\n",
    "        next_state = em.get_state()\n",
    "        memory.push(Experience(state, action, next_state, reward))\n",
    "        state = next_state\n",
    "        \n",
    "        if memory.can_provide_sample(batch_size):\n",
    "            experiences = memory.sample(batch_size)\n",
    "            states, actions, rewards, next_states = extract_tensors(experiences)\n",
    "            \n",
    "            current_q_values = QValues.get_current(policy_net,states, actions)\n",
    "            next_q_values = QValues.get_next(target_net, next_states)\n",
    "            target_q_values = (next_q_values * gamma) + rewards\n",
    "            \n",
    "            loss = F.mse_loss(current_q_values, target_q_values.unsqueeze(1))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        if em.done:\n",
    "            episode_durations.append(timestep)\n",
    "            plot(episode_durations,20)\n",
    "            break\n",
    "        \n",
    "    if episode % target_update == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "device = torch.device(\"cpu\")        \n",
    "policy_net = policy_net.to(device)\n",
    "target_net = target_net.to(device)\n",
    "agent.device = device\n",
    "'''torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\")        \n",
    "policy_net = policy_net.to(device)\n",
    "target_net = target_net.to(device)\n",
    "agent.device = device\n",
    "'''\n",
    "for episode in range(num_episodes):\n",
    "    em.reset()\n",
    "    state = em.get_state()\n",
    "    \n",
    "    for timestep in count():\n",
    "        action = agent.select_action(state,policy_net)\n",
    "        reward = em.take_action(action)\n",
    "        next_state = em.get_state()\n",
    "        memory.push(Experience(state, action, next_state, reward))\n",
    "        state = next_state\n",
    "        \n",
    "        if memory.can_provide_sample(batch_size):\n",
    "            experiences = memory.sample(batch_size)\n",
    "            states, actions, rewards, next_states = extract_tensors(experiences)\n",
    "            \n",
    "            current_q_values = QValues.get_current(policy_net,states, actions)\n",
    "            next_q_values = QValues.get_next(target_net, next_states)\n",
    "            target_q_values = (next_q_values * gamma) + rewards\n",
    "            \n",
    "            loss = F.mse_loss(current_q_values, target_q_values.unsqueeze(1))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        if em.done:\n",
    "            episode_durations.append(timestep)\n",
    "            plot(episode_durations,100)\n",
    "            break\n",
    "        \n",
    "    if episode % target_update == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "        \n",
    "em.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
